{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0239ba3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pubmed-scraper pymed lxml progress\n",
    "!pip install attrs certifi ipython pandas progress pytest\n",
    "!pip install requests urllib3 pyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4bc353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pubmed_data = pd.read_csv(\"/data/pubmed-data.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca05623",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "An implementation of the Token Bucket algorithm\n",
    "Author Dan Davis\n",
    "\"\"\"\n",
    "# NOTE: This code was adapted from https://github.com/porterjamesj/tokenbucket/blob/master/tokenbucket.py,\n",
    "#       but modified to add a backoff that appears to be needed on Windows.\n",
    "import time\n",
    "from threading import Lock\n",
    "from requests import Session\n",
    "\n",
    "\n",
    "__all__ = (\n",
    "    'TokenBucket',\n",
    "    'RateLimitedSession',\n",
    ")\n",
    "\n",
    "\n",
    "class TokenBucket(object):\n",
    "\n",
    "    def __init__(self, rate=1, tokens=0, capacity=100):\n",
    "        # immutable attributes\n",
    "        self.lock = Lock()\n",
    "        self._rate = rate\n",
    "        self._capacity = capacity\n",
    "        # mutable attributes\n",
    "        self._tokens = tokens\n",
    "        self._time = time.monotonic()\n",
    "\n",
    "    @property\n",
    "    def rate(self):\n",
    "        return self._rate\n",
    "\n",
    "    @property\n",
    "    def capacity(self):\n",
    "        return self._capacity\n",
    "\n",
    "    def _adjust(self):\n",
    "        \"\"\"\n",
    "        Update internal time and tokens\n",
    "        \"\"\"\n",
    "        now = time.monotonic()\n",
    "        elapsed = now - self._time\n",
    "\n",
    "        self._tokens = min(\n",
    "            self._capacity,\n",
    "            self._tokens + elapsed * self._rate\n",
    "        )\n",
    "        self._time = now\n",
    "\n",
    "    @property\n",
    "    def tokens(self):\n",
    "        \"\"\"\n",
    "        Publicly accessible view of how many tokens the bucket has.\n",
    "        \"\"\"\n",
    "        with self.lock:\n",
    "            self._adjust()\n",
    "            return self._tokens\n",
    "\n",
    "    def consume(self, tokens):\n",
    "        \"\"\"\n",
    "        Consume `tokens` tokens from the bucket, blocking until they are\n",
    "        available\n",
    "        \"\"\"\n",
    "        with self.lock:\n",
    "            self._adjust()\n",
    "            self._tokens -= tokens\n",
    "            backoff = 1\n",
    "            while self._tokens < 0:\n",
    "                to_sleep = backoff * (-self._tokens / self._rate)\n",
    "                time.sleep(to_sleep)\n",
    "                self._adjust()\n",
    "                backoff += 1\n",
    "\n",
    "\n",
    "class RateLimitedSession(Session):\n",
    "    def __init__(self, session=None, tokenbucket=None, rate=1, tokens=0, capacity=100, backoff=2.0,\n",
    "                 *args, **kwargs):\n",
    "        \"\"\"Creates a TokenBucketSession\n",
    "\n",
    "        Notes\n",
    "        ~~~~~\n",
    "\n",
    "        * If you provide a `tokenbucket`, then the `rate`, `tokens`, and `capacity` arguments are ignored.\n",
    "        \"\"\"\n",
    "        super(RateLimitedSession, self).__init__(*args, **kwargs)\n",
    "        if tokenbucket is None:\n",
    "            tokenbucket  = TokenBucket(rate=rate, tokens=tokens, capacity=capacity)\n",
    "        self.tokenbucket = tokenbucket\n",
    "        self.session = session\n",
    "        self.backoff = backoff\n",
    "\n",
    "    def request(self, *args, **kwargs):\n",
    "        \"\"\"Maintains the existing api for Session.request.\n",
    "\n",
    "        Used by all of the higher level methods, e.g. Session.get.\n",
    "        \"\"\"\n",
    "        if self.session:\n",
    "            func = self.session.request\n",
    "        else:\n",
    "            func = super(RateLimitedSession, self).request\n",
    "        self.tokenbucket.consume(1)\n",
    "        r = func(*args, **kwargs)\n",
    "        if r.status_code == 429:\n",
    "            time.sleep(self.backoff)\n",
    "            r = func(*args, **kwargs)\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c3f323",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author Dan Davis\n",
    "\"\"\"\n",
    "\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib.parse import quote\n",
    "from types import MethodType\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "from lxml import etree\n",
    "from io import BytesIO\n",
    "\n",
    "\n",
    "# Hostname for eutils\n",
    "EUTILS_PREFIX = 'https://eutils.ncbi.nlm.nih.gov/entrez'\n",
    "\n",
    "# Base URL for eutils\n",
    "EUTILS_URL = '{}/eutils/{}'\n",
    "\n",
    "\n",
    "class EUtils(object):\n",
    "    \"\"\"\n",
    "    An abstraction that wraps the NCBI E-Utilities\n",
    "    \"\"\"\n",
    "    def __init__(self, apikey=None, email=None, rate=3, prefix=None, session=None):\n",
    "        self.apikey = apikey\n",
    "        self.email = email\n",
    "        self.rate = rate\n",
    "        self.prefix = prefix if prefix else EUTILS_PREFIX\n",
    "        if not session:\n",
    "            session = RateLimitedSession(rate=rate, tokens=rate, capacity=rate)\n",
    "            session.mount('https://', HTTPAdapter(max_retries=3, pool_maxsize=10))\n",
    "        self.session = session\n",
    "\n",
    "    def params(self, db=None, **kwargs):\n",
    "        params = dict((k,v) for k,v in kwargs.items())\n",
    "        if db:\n",
    "            params['db'] = db\n",
    "        if self.apikey:\n",
    "            params['api_key'] = self.apikey\n",
    "        return '&'.join('{}={}'.format(key, quote(value)) for key, value in params.items())\n",
    "\n",
    "    def einfo(self, db=None, **kwargs):\n",
    "        params = self.params(db, retmode='xml', **kwargs)\n",
    "        url = EUTILS_URL.format(self.prefix, 'einfo.fcgi') + '?' + params\n",
    "        r = self.session.get(url)\n",
    "        r.raise_for_status()\n",
    "        content_type = r.headers['Content-Type']\n",
    "        if content_type.startswith('text/xml'):\n",
    "            r.xml = etree.parse(BytesIO(r.content))\n",
    "        return r\n",
    "\n",
    "    def esearch(self, db, history=True, webenv=None, query_key=None, retmax=20, **kwargs):\n",
    "        if history or webenv:\n",
    "            kwargs['usehistory'] = 'y'\n",
    "            if webenv:\n",
    "                kwargs['WebEnv'] = webenv\n",
    "            if query_key:\n",
    "                kwargs['query_key'] = query_key\n",
    "        params = self.params(db, retmode='xml', retmax=str(retmax), **kwargs)\n",
    "        url = EUTILS_URL.format(self.prefix, 'esearch.fcgi') + '?' + params\n",
    "        r = self.session.get(url)\n",
    "        r.raise_for_status()\n",
    "        content_type = r.headers['Content-Type']\n",
    "        if content_type.startswith('text/xml'):\n",
    "            r.xml = etree.parse(BytesIO(r.content))\n",
    "            webenv = r.xml.xpath('/eSearchResult/WebEnv')\n",
    "            r.webenv = webenv[0].text if webenv else None\n",
    "            query_key = r.xml.xpath('/eSearchResult/QueryKey')\n",
    "            r.query_key = query_key[0].text if query_key else None\n",
    "        return r\n",
    "\n",
    "    def efetch(self, db, *args, webenv=None, query_key=None, retmax=20, **kwargs):\n",
    "        if webenv:\n",
    "            kwargs['usehistory'] = 'y'\n",
    "            kwargs['WebEnv'] = webenv\n",
    "            if query_key:\n",
    "                kwargs['query_key'] = query_key\n",
    "        if len(args) > 0:\n",
    "            idlist = ','.join(str(arg) for arg in args)\n",
    "            params = self.params(db, retmode='xml', retmax=str(retmax), id=idlist, **kwargs)\n",
    "        else:\n",
    "            params = self.params(db, retmode='xml', retmax=str(retmax), **kwargs)\n",
    "        url = EUTILS_URL.format(self.prefix, 'efetch.fcgi') + '?' + params\n",
    "        r = self.session.get(url)\n",
    "        r.raise_for_status()\n",
    "        content_type = r.headers['Content-Type']\n",
    "        if content_type.startswith('text/xml'):\n",
    "            setattr(r, 'xml', etree.parse(BytesIO(r.content)))\n",
    "        return r\n",
    "\n",
    "    def epost(self, db, *args, webenv=None, **kwargs):\n",
    "        idlist = ','.join(str(arg) for arg in args)\n",
    "        if webenv:\n",
    "            kwargs['WebEnv'] = webenv\n",
    "        params = self.params(db, id=idlist, retmode='xml', **kwargs)\n",
    "        url = EUTILS_URL.format(self.prefix, 'epost.fcgi') + '?' + params\n",
    "        r = self.session.get(url)\n",
    "        r.raise_for_status()\n",
    "        content_type = r.headers['Content-Type']\n",
    "        if content_type.startswith('text/xml'):\n",
    "            setattr(r, 'xml', etree.parse(BytesIO(r.content)))\n",
    "            webenv = r.xml.xpath('/ePostResult/WebEnv')\n",
    "            r.webenv = webenv[0].text if webenv else None\n",
    "            query_key = r.xml.xpath('/ePostResult/QueryKey')\n",
    "            r.query_key = query_key[0].text if query_key else None\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e471a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author Dan Davis\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import pandas as pd\n",
    "from attrs import define, field\n",
    "from numpy.random import RandomState\n",
    "from progress.bar import Bar\n",
    "from yaml import safe_load\n",
    "\n",
    "PREVIEW_PREFIX = 'https://eutilspreview.ncbi.nlm.nih.gov/entrez'\n",
    "\n",
    "@define\n",
    "class Config:\n",
    "    api_key: Optional[str]\n",
    "    email: Optional[str]\n",
    "    rate_limit: int\n",
    "    num_queries: int\n",
    "    num_results: int\n",
    "    data_path: str\n",
    "    data_sep: str\n",
    "    result_path: str\n",
    "    hedge_path: str\n",
    "    seed: int\n",
    "\n",
    "    @property\n",
    "    def random_state(self):\n",
    "        return RandomState(self.seed) if self.seed > 0 else None\n",
    "\n",
    "    @staticmethod\n",
    "    def get_defaults():\n",
    "        return {\n",
    "            'num_queries': 1000,\n",
    "            'num_results': 200,\n",
    "            'seed': -1,                             # seed below 0 is ignored\n",
    "            'data_path': '/data/pubmed-data.tsv',\n",
    "            'data_sep': '\\t',\n",
    "            'result_path': '/data/team4/results',\n",
    "            'hedge_path': '/data/team4/hedges.csv',\n",
    "            'api_key': None,\n",
    "            'email': None,\n",
    "            'rate_limit': 3\n",
    "        }\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, path=None):\n",
    "        cls_kwargs = cls.get_defaults()\n",
    "        expected_keys = set(cls_kwargs.keys())\n",
    "        if path is not None:\n",
    "            with open(str(path)) as f:\n",
    "                overrides = safe_load(f)\n",
    "            if any(key not in expected_keys for key in overrides.keys()):\n",
    "                raise ValueError(f'{path}: invalid setting encountered')\n",
    "            cls_kwargs.update(overrides)\n",
    "        return cls(**cls_kwargs)\n",
    "\n",
    "\n",
    "class Pipeline:\n",
    "    def __init__(self, config : Config):\n",
    "        self.config = config\n",
    "        self.hedge = None\n",
    "        self.data = None\n",
    "        self.eutils = EUtils(config.api_key, config.email, config.rate_limit, PREVIEW_PREFIX)\n",
    "\n",
    "    def load_hedges(self, hedge_path: Optional[str] = None):\n",
    "        if hedge_path is None:\n",
    "            hedge_path = self.config.hedge_path\n",
    "        # TODO: validate expected columns and types?\n",
    "        return pd.read_csv(hedge_path, index_col='BiasDimension')\n",
    "\n",
    "    def load_data(self, data_path: Optional[str] = None):\n",
    "        if data_path is None:\n",
    "            data_path = self.config.data_path\n",
    "        df = pd.read_csv(data_path, sep=self.config.data_sep)\n",
    "        # remove rows without query\n",
    "        df = df[df.query_term.notnull()]\n",
    "        return df\n",
    "\n",
    "    def stage1(self, result_path=None):\n",
    "        # prepare the run\n",
    "        self.hedge = self.load_hedges()\n",
    "        self.data = self.load_data()\n",
    "\n",
    "        num_queries = self.config.num_queries\n",
    "        queries = self.data.sample(num_queries, random_state=self.config.random_state)\n",
    "        # drop some of the columns to make this tractable\n",
    "        columns_to_drop = list(set(queries.columns) - {'search_id', 'query_term', 'result_count'})\n",
    "        queries = queries.drop(columns=columns_to_drop)\n",
    "\n",
    "        # setup the result directory\n",
    "        if result_path is None:\n",
    "            result_path = datetime.now().strftime('%Y-%m-%dT%H:%M:%S')\n",
    "        result_path = Path(self.config.result_path) / result_path\n",
    "        result_path.mkdir()\n",
    "\n",
    "        # progress bar\n",
    "        progress = Bar('Sage 1', max=self.config.num_queries)\n",
    "\n",
    "        # for each query\n",
    "        eutils = self.eutils\n",
    "        for index, row in self.queries.iterrows():\n",
    "            query_term = row['query_term']\n",
    "\n",
    "            # that query gets a directory\n",
    "            query_result_path = result_path / str(index)\n",
    "            query_result_path.mkdir()\n",
    "            relevance_results = query_result_path / 'relevance.xml'\n",
    "            datedesc_results = query_result_path / 'datedesc.xml'\n",
    "\n",
    "            # save the query results with relevance\n",
    "            r = eutils.esearch('pumed', retmax=self.config.num_results, term=query_term, sort='relevance')\n",
    "            relevance_results.write_text(r.content)\n",
    "\n",
    "            # save the query results with date descending\n",
    "            r = eutils.esearch('pubmed', retmax=self.config.num_results, term=query_term, sort='date_desc')\n",
    "            datedesc_results.write_text(r.content)\n",
    "\n",
    "            progress.next()\n",
    "        progress.finish()\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4704229d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eutils = EUtils(\n",
    "    '',               # API key\n",
    "    '',                                 # Email address - unused\n",
    "    10,                                                   # API calls per second\n",
    "    'https://eutilspreview.ncbi.nlm.nih.gov/entrez'       # URL prefix for preview - normally not needed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2676204a",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.headers['Content-Type'].startswith('text/xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffc92a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = eutils.esearch('pubmed', term='African Americans', sort='relevance', retmax=200)\n",
    "print(r.webenv)\n",
    "print(r.query_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c6fc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = eutils.esearch('pubmed', term='African Americans', retmax=5000000)\n",
    "print_element(r.xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de7e34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pmids = [element.text for element in r.xml.xpath('//IdList/Id')]\n",
    "\n",
    "pmids = [ '18538731' \n",
    ", '31761807' \n",
    ", '28244479' \n",
    ", '29949179' \n",
    ", '27741350' \n",
    ", '28574057' \n",
    ", '27839715' \n",
    ", '33024261' \n",
    ", '24274180' \n",
    ", '29770138' \n",
    ", '33173229' \n",
    ", '26111503' \n",
    ", '29217838' \n",
    ", '29397066' \n",
    ", '30480571' \n",
    ", '28351568' \n",
    ", '16892035' \n",
    ", '30593508' \n",
    ", '29032295' \n",
    ", '23266771' \n",
    ", '35612878' \n",
    ", '35612872' \n",
    ", '35612856' \n",
    ", '35612854' \n",
    ", '35612853' \n",
    ", '35612849' \n",
    ", '35612841' \n",
    ", '35612839' \n",
    ", '35612832' \n",
    ", '35612829' \n",
    ", '35612824' \n",
    ", '35612815' \n",
    ", '35612791' \n",
    ", '35612789' \n",
    ", '35612777' \n",
    ", '35612774' \n",
    ", '35612771' \n",
    ", '35612766' \n",
    ", '35612761' \n",
    ", '35612745' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d37fa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = eutils.esearch('pubmed', term='African Americans', sort='relevance', retmax=5000)\n",
    "print(r.webenv)\n",
    "print(r.query_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ee0f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmids = [element.text for element in r.xml.xpath('//IdList/Id')]\n",
    "\n",
    "r = eutils.epost('pubmed', *pmids, webenv=r.webenv)\n",
    "print_element(r.xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14a735b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = eutils.esearch('pubmed', term='cancer', sort='date', webenv=r3.webenv, query_key=r2.query_key, retmax=500)\n",
    "\n",
    "print_element(r2.xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b6e353",
   "metadata": {},
   "outputs": [],
   "source": [
    "r3 = eutils.epost('pubmed', *pmids2, webenv=r3.webenv)\n",
    "\n",
    "print_element(r3.xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aa8907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lxml.etree as ET\n",
    "\n",
    "filename = 'term_cancer_sort_date.xml'\n",
    "r3.xml.write(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7058211",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, FileLink\n",
    "local_file = FileLink('./term_cancer_sort_date.xml', result_html_prefix=\"download:\")\n",
    "display(local_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
